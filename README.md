# Hydrosat Azure Challenge ğŸš€

# Hydrosat Geospatial Pipeline

A daily-partitioned geospatial data processing pipeline deployed on Azure Kubernetes Service using Dagster for orchestration.

## Overview

This project implements a data pipeline that:
- Processes geospatial data within defined bounding boxes
- Handles multiple field polygons with different planting dates
- Runs daily partitions with dependencies on previous days
- Stores results in Azure Blob Storage

## Project Structure
hydrosat-task/
â”œâ”€â”€ README.md # Project overview (this file)
â”œâ”€â”€ INSTRUCTIONS.md # Setup and deployment instructions
â”œâ”€â”€ ARCHITECTURE.md # System architecture documentation
â”œâ”€â”€ deploy.sh # One-click deployment script
â”œâ”€â”€ terraform/ # Infrastructure as Code
â”‚ â”œâ”€â”€ main.tf # Azure resources definition
â”‚ â”œâ”€â”€ variables.tf # Configurable parameters
â”‚ â””â”€â”€ outputs.tf # Resource outputs
â”œâ”€â”€ dagster/ # Dagster application
â”‚ â”œâ”€â”€ Dockerfile # Container definition
â”‚ â”œâ”€â”€ workspace.yaml # Dagster workspace config
â”‚ â”œâ”€â”€ pyproject.toml # Python dependencies
â”‚ â””â”€â”€ hydrosat_project/ # Python code module
â”‚ â”œâ”€â”€ init.py # Module initialization
â”‚ â”œâ”€â”€ assets.py # Dagster assets definition
â”‚ â””â”€â”€ resources.py # Azure resources configuration
â””â”€â”€ helm/ # Kubernetes deployment
â””â”€â”€ dagster-values.yaml # Helm chart configuration

## Inputs

Upload once:

```bash
az storage blob upload-batch -s inputs/ -d inputs --account-name <storage>
```

* `bbox.json` â€“ bounding rectangle `[xmin,ymin,xmax,ymax]`
* `fields.geojson` â€“ polygons you drew via [https://geojson.io](https://geojson.io)

## Quick Start

1. Make sure prerequisites are installed (see INSTRUCTIONS.md)
2. Run the deployment script:


```bash
./deploy.sh               # takes ~15â€¯min
# open dagster UI
```
3. Follow the instructions to access the Dagster UI
4. Materialize assets to process geospatial data

## Features

- **Daily Partitioning**: Process data in daily increments
- **Partition Dependencies**: Each day depends on the previous day's results
- **Geospatial Processing**: Filter fields by bounding box and planting date
- **Azure Integration**: Store inputs and outputs in Azure Blob Storage



## AI disclosure

Text, code, and the architecture diagram were drafted with **OpenAI o3** (ChatGPT) and reviewed by a human.

---

Enjoy â˜€ï¸ â€“ PRs welcome!